<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>Modelling - <b><font style="Times New Roman">Predicting Broker Performance for 2019</font></b></title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">

        <script src="../js/jquery-1.10.2.min.js" defer></script>
        <script src="../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href=".."><b><font style="Times New Roman">Predicting Broker Performance for 2019</font></b></a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href=".." class="nav-link">Home</a>
                            </li>
                            <li class="navitem">
                                <a href="../EDA/" class="nav-link">Data Analysis</a>
                            </li>
                            <li class="navitem">
                                <a href="../Clustering/" class="nav-link">Clustering & PCA</a>
                            </li>
                            <li class="navitem active">
                                <a href="./" class="nav-link">Modelling</a>
                            </li>
                            <li class="navitem">
                                <a href="../Results.md" class="nav-link">Results</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../Clustering/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" class="nav-link disabled">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="2"><a href="#gwp-2018-prediction" class="nav-link">GWP 2018 Prediction</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#classification-trees" class="nav-link">Classification Trees</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#logistic-regression" class="nav-link">Logistic Regression</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#random-forest" class="nav-link">Random Forest</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#results-gwp-2019" class="nav-link">Results: GWP 2019</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#gwp-2019-prediction" class="nav-link">GWP 2019 Prediction</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#classification-trees_1" class="nav-link">Classification Trees</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#logistic-regression_1" class="nav-link">Logistic Regression</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#results-gwp-2019_1" class="nav-link">Results: GWP 2019</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="2"><a href="#conclusion" class="nav-link">Conclusion</a>
              <ul class="nav flex-column">
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h2 id="gwp-2018-prediction"><b><span style="font-family: Book Antiqua; font-size: 0.8em;">GWP 2018 Prediction</b></h2>
<p><span style="font-family: Times New Roman; font-size: 1em;">For prediction of Gross Written Premium for 2019 we need to first predict for 2018 to test our model accuracy. 
Since we are primarily interested in determing whether GWP increases or decreases for the upcoming year for each broker, a new column called "Up_Down" can be created that compares GWP 2018 values to GWP 2017 and labels the values as "Up" if GWP for 2018 exceeds 2017 and "Down" if GWP for 2018 is lower than 2017.
The response variable is a factor (character variable), we have to use machine learning algorithms such as classification trees, logistic regression, etc.
The new dataframe: “myBroker_exp_DF” consists of all variables from 2015 to 2017. Variables from years 2013 and 2014 are excluded, and the new variable: "Up_Down" is added.</p>
<pre><code class="r"># Prediction of GWP2018

set.seed(12345)

Up_Down &lt;- character(length(myBDF$GWP_2018))
Up_Down[myBDF$GWP_2017 &lt; myBDF$GWP_2018] &lt;- &quot;Up&quot;
Up_Down[myBDF$GWP_2017 &gt;= myBDF$GWP_2018] &lt;- &quot;Down&quot;


myBroker_exp_DF &lt;- myBDF %&gt;%
  dplyr::mutate(quote_ratio2015 = QuoteCount_2015/ Submissions_2015,
                quote_ratio2016 = QuoteCount_2016/ Submissions_2016,
                quote_ratio2017 = QuoteCount_2017/ Submissions_2017,
                hit_ratio15 = PolicyCount_2015/ QuoteCount_2015,
                hit_ratio16 = PolicyCount_2016/ QuoteCount_2016,
                hit_ratio17 = PolicyCount_2017/ QuoteCount_2017,
                success_ratio15_17 = PolicyCount_2015+ PolicyCount_2016 + PolicyCount_2017/
                  Submissions_2015 + Submissions_2016 + Submissions_2017,
                Up_Down) %&gt;%
  select(-GWP_2018, -Submissions_2018, -QuoteCount_2018, -PolicyCount_2018, -AvgQuote_2018, -AvgTIV_2018, 
         -Submissions_2014, -QuoteCount_2013, -QuoteCount_2014, -AvgQuote_2013, -AvgQuote_2014)

myBroker_exp_DF$Up_Down &lt;- as.factor(myBroker_exp_DF$Up_Down)

myBrokerDF &lt;- myBroker_exp_DF

colnames(myBrokerDF) &lt;- c(&quot;Submissions_3&quot;,  &quot;Submissions_2&quot;,    &quot;Submissions_1&quot;,
                          &quot;QuoteCount_3&quot;,&quot;QuoteCount_2&quot;,    &quot;QuoteCount_1&quot;, &quot;AvgQuote_3&quot;,   &quot;AvgQuote_2&quot;,   
                          &quot;AvgQuote_1&quot;, &quot;PolicyCount_3&quot;,    &quot;PolicyCount_2&quot;,    &quot;PolicyCount_1&quot;,    
                          &quot;GWP_3&quot;,  &quot;GWP_2&quot;,    &quot;GWP_1&quot;,    &quot;AvgTIV_3&quot;, &quot;AvgTIV_2&quot;,
                          &quot;AvgTIV1&quot;, &quot;QR3&quot;, &quot;QR2&quot;, &quot;QR1&quot;, &quot;HR3&quot;, &quot;HR2&quot;, &quot;HR1&quot;,&quot;SR&quot;,&quot;Up_Down&quot;)
</code></pre>

<p><span style="font-family: Times New Roman; font-size: 1em;">We then proceed to partition the dataset into test (20%) and training (80%) using the function “createDataPartition” (found in the "caret" package). </p>
<pre><code class="r"># Partitioning into training and test, training = 80% as the dataset is small
trainRows &lt;- createDataPartition(Up_Down, 
                                 p = 0.8, 
                                 list=FALSE)

BrokTrainData18 &lt;- myBrokerDF[trainRows,]
BrokTestData18 &lt;- myBrokerDF[-trainRows,]

table(Up_Down)
</code></pre>

<pre><code>## Up_Down
## Down   Up 
##  106   82
</code></pre>
<h2 id="classification-trees"><b><span style="font-family: Book Antiqua; font-size: 0.8em;">Classification Trees</b></h2>
<p><span style="font-family: Times New Roman; font-size: 1em;">For the classification tree model, we use all variables in the training set to train the model. 
To train the model, we use the train function and save the results in "“myRparttune”, apply the “rpart” method, and set the metric to “ROC” to ensure the selection of best model. 
For tuning the model we need to include; tunelength = 10, default being 3, and split criteria set to “information gain”, default is Gini Index. 
The train function provided the best model at complexity parameter = 0.07.</p>
<pre><code class="r"># Rpart
# increasing tune length &amp; split type as 'Entropy'

splitEntropy = list(split = c(&quot;information&quot;))

myRparttune &lt;- train(Up_Down ~ ., 
                     data=BrokTrainData18, 
                     method=&quot;rpart&quot;,
                     metric=&quot;ROC&quot;,
                     tuneLength = 10,
                     parms = splitEntropy,
                     trControl=trainControl(classProbs=TRUE,
                                            summaryFunction=twoClassSummary))


plot(myRparttune)
</code></pre>

<p><img alt="" src="../Images/image22.jpg" /><!-- --></p>
<pre><code class="r">myRparttune$results
</code></pre>

<pre><code>##            cp       ROC      Sens      Spec      ROCSD    SensSD    SpecSD
## 1  0.00000000 0.7087193 0.7030466 0.6596959 0.06744125 0.1134558 0.1158620
## 2  0.03535354 0.7025369 0.7053459 0.6661077 0.07400825 0.1096479 0.1015546
## 3  0.07070707 0.6943522 0.7022634 0.6420807 0.07094654 0.1119068 0.1225912
## 4  0.10606061 0.6882251 0.6545418 0.6915282 0.07224751 0.1549664 0.1601590
## 5  0.14141414 0.6809741 0.6552857 0.6663226 0.08001456 0.1753808 0.1887295
## 6  0.17676768 0.6757820 0.6695795 0.6547226 0.07962344 0.1698370 0.2027911
## 7  0.21212121 0.6703244 0.6802461 0.6307015 0.08585172 0.1801601 0.2446506
## 8  0.24747475 0.6499109 0.6265344 0.6665035 0.08323140 0.1763311 0.2818400
## 9  0.28282828 0.6260870 0.6584177 0.5937563 0.09149758 0.1980458 0.3535952
## 10 0.31818182 0.6106691 0.6954677 0.5258706 0.09481431 0.2145107 0.3797248
</code></pre>
<pre><code class="r">myRparttune$bestTune # best model with cp
</code></pre>

<pre><code>##   cp
## 1  0
</code></pre>
<pre><code class="r">myRparttune$finalModel
</code></pre>

<pre><code>## n= 151 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
##  1) root 151 66 Down (0.56291391 0.43708609)  
##    2) PolicyCount_1&lt; 45.5 52  6 Down (0.88461538 0.11538462) *
##    3) PolicyCount_1&gt;=45.5 99 39 Up (0.39393939 0.60606061)  
##      6) AvgQuote_1&lt; 30219.13 58 23 Down (0.60344828 0.39655172)  
##       12) AvgTIV1&gt;=7156371 29  5 Down (0.82758621 0.17241379) *
##       13) AvgTIV1&lt; 7156371 29 11 Up (0.37931034 0.62068966)  
##         26) HR2&gt;=0.7449327 10  3 Down (0.70000000 0.30000000) *
##         27) HR2&lt; 0.7449327 19  4 Up (0.21052632 0.78947368) *
##      7) AvgQuote_1&gt;=30219.13 41  4 Up (0.09756098 0.90243902) *
</code></pre>
<pre><code class="r">print(myRparttune)
</code></pre>

<pre><code>## CART 
## 
## 151 samples
##  25 predictor
##   2 classes: 'Down', 'Up' 
## 
## No pre-processing
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 151, 151, 151, 151, 151, 151, ... 
## Resampling results across tuning parameters:
## 
##   cp          ROC        Sens       Spec     
##   0.00000000  0.7087193  0.7030466  0.6596959
##   0.03535354  0.7025369  0.7053459  0.6661077
##   0.07070707  0.6943522  0.7022634  0.6420807
##   0.10606061  0.6882251  0.6545418  0.6915282
##   0.14141414  0.6809741  0.6552857  0.6663226
##   0.17676768  0.6757820  0.6695795  0.6547226
##   0.21212121  0.6703244  0.6802461  0.6307015
##   0.24747475  0.6499109  0.6265344  0.6665035
##   0.28282828  0.6260870  0.6584177  0.5937563
##   0.31818182  0.6106691  0.6954677  0.5258706
## 
## ROC was used to select the optimal model using the largest value.
## The final value used for the model was cp = 0.
</code></pre>
<pre><code class="r">par(xpd = NA)
plot(myRparttune$finalModel)
text(myRparttune$finalModel, cex=.6)
</code></pre>

<p><img alt="" src="../Images/image23.jpg" /><!-- --></p>
<pre><code class="r">myRparttunepredtest &lt;- predict(myRparttune, newdata=BrokTestData18)
(myRparttunedConfusion &lt;- table(BrokTestData18$Up_Down, myRparttunepredtest))
</code></pre>

<pre><code>##       myRparttunepredtest
##        Down Up
##   Down   17  4
##   Up      3 13
</code></pre>
<pre><code class="r">1-sum(diag(myRparttunedConfusion))/sum(myRparttunedConfusion)
</code></pre>

<pre><code>## [1] 0.1891892
</code></pre>
<pre><code class="r">myRparttunedpred &lt;- predict(myRparttune, newdata=myBrokerDF)
(myRparttunedCM &lt;- table(myBrokerDF$Up_Down, myRparttunedpred))
</code></pre>

<pre><code>##       myRparttunedpred
##        Down Up
##   Down   94 12
##   Up     17 65
</code></pre>
<pre><code class="r">1-sum(diag(myRparttunedCM))/sum(myRparttunedCM)
</code></pre>

<pre><code>## [1] 0.1542553
</code></pre>
<pre><code class="r">myRparttunePredict &lt;- predict(myRparttune, newdata=myBrokerDF, type=&quot;prob&quot;)
myRparttunePred &lt;- prediction(myRparttunePredict[,2], 
                              myBrokerDF$Up_Down,
                              label.ordering=c( &quot;Down&quot;, &quot;Up&quot;))
myRparttunePerf &lt;- performance(myRparttunePred, &quot;tpr&quot;, &quot;fpr&quot;)

performance(myRparttunePred, &quot;auc&quot;)
</code></pre>

<pre><code>## An object of class "performance"
## Slot "x.name":
## [1] "None"
## 
## Slot "y.name":
## [1] "Area under the ROC curve"
## 
## Slot "alpha.name":
## [1] "none"
## 
## Slot "x.values":
## list()
## 
## Slot "y.values":
## [[1]]
## [1] 0.8584906
## 
## 
## Slot "alpha.values":
## list()
</code></pre>
<p><span style="font-family: Times New Roman; font-size: 1em;">The misclassification rate for the classification tree model when validating on the test data set (myRparttunepredtest) was 24.32 %. The accuracy rate for the model was 75.68%. 
The matrix represents a total of 13 observations correctly classified as “Up” and 15 observations correctly classified as “Down”. 
<br>The misclassification rate for classification tree model when validated using the entire data set (myRparttunedpred) is 18.62 %. The accuracy rate for this model is 81.38%. The matrix shows a total of 68 observations correctly classified as “Up” and 85 observations correctly classified as “Down”.
<br>The variables that appear to be important for predicting the outcome for the gross written premium prediction for 2018 are Policy Counts, Average Quote, and Average Total Insured Value. </p>
<h2 id="logistic-regression"><b><span style="font-family: Book Antiqua; font-size: 0.8em;">Logistic Regression</b></h2>
<p><span style="font-family: Times New Roman; font-size: 1em;">The logistic regression model using the training dataset (BrokTrainData18): Weights are not assigned as there is “little” to “no” class imbalance (Up: 82, Dow: 106). 
To train the model, we use the train function (and store results in “myLRtrain”), apply the “glm” method and set the metric to “ROC”. </p>
<pre><code class="r"># Logistic regression
#The tuneLength parameter is used to determine the total number of combinations that will be evaluated

myLRtrain &lt;- train(Up_Down ~ ., 
                   data=BrokTrainData18, 
                   method=&quot;glm&quot;,
                   metric=&quot;ROC&quot;,
                   tuneLength = 10,
                   trControl=trainControl(classProbs=TRUE,
                                          summaryFunction=twoClassSummary))
</code></pre>

<pre><code class="r">myLRtrain$results
</code></pre>

<pre><code>##   parameter       ROC      Sens      Spec      ROCSD     SensSD    SpecSD
## 1      none 0.7701864 0.7088419 0.6758822 0.06620168 0.09827614 0.1016044
</code></pre>
<pre><code class="r">myLRtrain$bestTune
</code></pre>

<pre><code>##   parameter
## 1      none
</code></pre>
<pre><code class="r">myLRtrain$finalModel
</code></pre>

<pre><code>## 
## Call:  NULL
## 
## Coefficients:
##   (Intercept)  Submissions_3  Submissions_2  Submissions_1   QuoteCount_3  
##     9.596e-01     -5.909e-03     -3.232e+00     -3.234e+00      8.027e-03  
##  QuoteCount_2   QuoteCount_1     AvgQuote_3     AvgQuote_2     AvgQuote_1  
##    -1.148e-02     -5.399e-03      3.276e-05     -1.346e-05      2.173e-04  
## PolicyCount_3  PolicyCount_2  PolicyCount_1          GWP_3          GWP_2  
##    -3.280e+00     -3.243e+00      7.454e-02     -6.097e-07     -6.275e-07  
##         GWP_1       AvgTIV_3       AvgTIV_2        AvgTIV1            QR3  
##     4.961e-07      8.505e-07     -1.898e-07     -1.563e-06     -4.295e+00  
##           QR2            QR1            HR3            HR2            HR1  
##     1.361e+00      2.944e-01     -7.731e-01     -1.279e-01     -1.896e+00  
##            SR  
##     3.239e+00  
## 
## Degrees of Freedom: 150 Total (i.e. Null);  125 Residual
## Null Deviance:       206.9 
## Residual Deviance: 95.49     AIC: 147.5
</code></pre>
<pre><code class="r">print(myLRtrain)
</code></pre>

<pre><code>## Generalized Linear Model 
## 
## 151 samples
##  25 predictor
##   2 classes: 'Down', 'Up' 
## 
## No pre-processing
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 151, 151, 151, 151, 151, 151, ... 
## Resampling results:
## 
##   ROC        Sens       Spec     
##   0.7701864  0.7088419  0.6758822
</code></pre>
<pre><code class="r">myLRtraintest &lt;- predict(myLRtrain, newdata=BrokTestData18)
(myLRtrainConfusion &lt;- table(BrokTestData18$Up_Down, myLRtraintest))
</code></pre>

<pre><code>##       myLRtraintest
##        Down Up
##   Down   15  6
##   Up      3 13
</code></pre>
<pre><code class="r">1-sum(diag(myLRtrainConfusion))/sum(myLRtrainConfusion)
</code></pre>

<pre><code>## [1] 0.2432432
</code></pre>
<pre><code class="r">myLRtrainpred &lt;- predict(myLRtrain, newdata=myBrokerDF)
myLRtrainprob &lt;- predict(myLRtrain, newdata=myBrokerDF, type = &quot;prob&quot;)[,2]
(myLRtrainCM &lt;- table(myBrokerDF$Up_Down, myLRtrainpred))
</code></pre>

<pre><code>##       myLRtrainpred
##        Down Up
##   Down   87 19
##   Up     18 64
</code></pre>
<pre><code class="r">1-sum(diag(myLRtrainCM))/sum(myLRtrainCM)
</code></pre>

<pre><code>## [1] 0.1968085
</code></pre>
<pre><code class="r"># ROC for Logistic regression
myLRPredict &lt;- predict(myLRtrain, newdata=myBrokerDF, type=&quot;prob&quot;)
myLRPred &lt;- prediction(myLRPredict[,2], 
                       myBrokerDF$Up_Down,
                       label.ordering=c( &quot;Down&quot;, &quot;Up&quot;))
myLRPerf &lt;- performance(myLRPred, &quot;tpr&quot;, &quot;fpr&quot;)

performance(myLRPred, &quot;auc&quot;)
</code></pre>

<pre><code>## An object of class "performance"
## Slot "x.name":
## [1] "None"
## 
## Slot "y.name":
## [1] "Area under the ROC curve"
## 
## Slot "alpha.name":
## [1] "none"
## 
## Slot "x.values":
## list()
## 
## Slot "y.values":
## [[1]]
## [1] 0.9111827
## 
## 
## Slot "alpha.values":
## list()
</code></pre>
<p><span style="font-family: Times New Roman; font-size: 1em;">The misclassification rate for the logistic regression model on the test set (myLRtraintest) is 24.32%. 
<br>The accuracy rate for the model is 75.68%. The misclassification rate for the logistic regression model when validating the entire data set (myLRtrainpred) is 19.68%. 
The accuracy rate for the model is 80.32%. The confusion matrix shows that 64 observations were correctly classified as “Up” and 87 correctly classified as “Down”. 
<br>The features that were found to be most important for prediction are average quote counts for 2015, average total insured value for 2015 and 2017, hit ratio for 2015.</p>
<h2 id="random-forest"><b><span style="font-family: Book Antiqua; font-size: 0.8em;">Random Forest</b></h2>
<p><span style="font-family: Times New Roman; font-size: 1em;">To train the model using Random Forest algorithm, the method specified as “rf”, the metric set to “ROC”, 
and the number of trees set to 1500 (as overfitting is not a concern with Random Forest).<br />
The response column “Up_Down” needs to be set to “factor” before proceeding. 
We can evaluate our model first before tuning (with 500 trees) and then with 1500 trees.</p>
<pre><code class="r"># Random Forest with cross validation &amp; tuning the no. of trees 
# (as overfitting is not a concern with Random Forest)
no_trees &lt;- 1500  # no. of trees

myRFtune &lt;- train(Up_Down ~ ., 
                  data=BrokTrainData18, 
                  method=&quot;rf&quot;,
                  metric=&quot;ROC&quot;,
                  ntree = no_trees,
                  trControl=trainControl(classProbs=TRUE,
                                         summaryFunction=twoClassSummary))


plot(myRFtune)
</code></pre>

<p><img alt="" src="../Images/image24.jpg" /><!-- --></p>
<pre><code class="r">myRFtune$results
</code></pre>

<pre><code>##   mtry       ROC      Sens      Spec      ROCSD     SensSD    SpecSD
## 1    2 0.8114030 0.7398858 0.6991620 0.04372114 0.09167648 0.1392029
## 2   13 0.8200906 0.7570010 0.7278308 0.04157764 0.08786922 0.1086326
## 3   25 0.8185020 0.7615775 0.7062938 0.04014404 0.09534216 0.1127736
</code></pre>
<pre><code class="r">myRFtune$bestTune
</code></pre>

<pre><code>##   mtry
## 2   13
</code></pre>
<pre><code class="r">myRFtune$finalModel
</code></pre>

<pre><code>## 
## Call:
##  randomForest(x = x, y = y, ntree = ..1, mtry = param$mtry) 
##                Type of random forest: classification
##                      Number of trees: 1500
## No. of variables tried at each split: 13
## 
##         OOB estimate of  error rate: 26.49%
## Confusion matrix:
##      Down Up class.error
## Down   67 18   0.2117647
## Up     22 44   0.3333333
</code></pre>
<pre><code class="r">myRFtunedpredtest &lt;- predict(myRFtune, newdata=BrokTestData18)
(myRFtunedConfusion &lt;- table(BrokTestData18$Up_Down, myRFtunedpredtest))
</code></pre>

<pre><code>##       myRFtunedpredtest
##        Down Up
##   Down   16  5
##   Up      5 11
</code></pre>
<pre><code class="r">1-sum(diag(myRFtunedConfusion))/sum(myRFtunedConfusion)
</code></pre>

<pre><code>## [1] 0.2702703
</code></pre>
<pre><code class="r">myRFtunedpred &lt;- predict(myRFtune, newdata=myBrokerDF)
(myRFtunedConfusion &lt;- table(myBrokerDF$Up_Down, myRFtunedpred))
</code></pre>

<pre><code>##       myRFtunedpred
##        Down  Up
##   Down  101   5
##   Up      5  77
</code></pre>
<pre><code class="r">plot(myRFtune)
</code></pre>

<p><img alt="" src="../Images/image25.jpg" /><!-- --></p>
<pre><code class="r">1-sum(diag(myRFtunedConfusion))/sum(myRFtunedConfusion)
</code></pre>

<pre><code>## [1] 0.05319149
</code></pre>
<p><span style="font-family: Times New Roman; font-size: 1em;">The misclassification rate for the random forest model when validating using the test set (myRFtunedpredtest) is 27.03%. 
The accuracy rate for the model was 72.97%.<br />
The misclassification rate for the random forest model when validating the entire data set (myLRtrainpred) is 5.31%. 
The accuracy rate for the model was 94.69%. 
<br>The OOB estimate error rate for random forest, with default 500 as number of trees was 30.46%. 
The OOB estimate error rate for random forest, with default 1500 as number of trees was 27.81%</p>
<pre><code class="r">myRFtunePredict &lt;- predict(myRFtune, newdata=myBrokerDF, type=&quot;prob&quot;)
myRFtunePred &lt;- prediction(myRFtunePredict[,2], 
                           myBrokerDF$Up_Down,
                           label.ordering=c( &quot;Down&quot;, &quot;Up&quot;))
myRFtunePerf &lt;- performance(myRFtunePred, &quot;tpr&quot;, &quot;fpr&quot;)

# Plotting ROC curves

plot(myRFtunePerf, col=1)
plot(myLRPerf, col=2, add=TRUE)
plot(myRparttunePerf, col=3, add=TRUE)
legend(0.7, 0.6, c(&quot;Random Forest&quot;, &quot;Log. Reg.&quot;, &quot;Class. Tree&quot;), col=1:3, lwd=3)
</code></pre>

<p><img alt="" src="../Images/image26.jpg" /><!-- --></p>
<pre><code class="r"># Calculating AUC for all models

performance(myRparttunePred, &quot;auc&quot;)
</code></pre>

<pre><code>## An object of class "performance"
## Slot "x.name":
## [1] "None"
## 
## Slot "y.name":
## [1] "Area under the ROC curve"
## 
## Slot "alpha.name":
## [1] "none"
## 
## Slot "x.values":
## list()
## 
## Slot "y.values":
## [[1]]
## [1] 0.8584906
## 
## 
## Slot "alpha.values":
## list()
</code></pre>
<pre><code class="r">performance(myLRPred, &quot;auc&quot;)
</code></pre>

<pre><code>## An object of class "performance"
## Slot "x.name":
## [1] "None"
## 
## Slot "y.name":
## [1] "Area under the ROC curve"
## 
## Slot "alpha.name":
## [1] "none"
## 
## Slot "x.values":
## list()
## 
## Slot "y.values":
## [[1]]
## [1] 0.9111827
## 
## 
## Slot "alpha.values":
## list()
</code></pre>
<pre><code class="r">performance(myRFtunePred, &quot;auc&quot;)
</code></pre>

<pre><code>## An object of class "performance"
## Slot "x.name":
## [1] "None"
## 
## Slot "y.name":
## [1] "Area under the ROC curve"
## 
## Slot "alpha.name":
## [1] "none"
## 
## Slot "x.values":
## list()
## 
## Slot "y.values":
## [[1]]
## [1] 0.9932121
## 
## 
## Slot "alpha.values":
## list()
</code></pre>
<h2 id="results-gwp-2019"><b><span style="font-family: Book Antiqua; font-size: 0.8em;">Results: GWP 2019</b></h2>
<p><span style="font-family: Times New Roman; font-size: 1em;">Performance for the classification tree model, the logistic regression model and random forest model are 
represented by the green (Class Tree), red (Log Reg) and the black (Random Forest) curves. 
The AUC for the Classification Trees is 84.92, the AUC for the Logistic Regression is 91.12 and the AUC for Random Forest is 99.33</p>
<h2 id="gwp-2019-prediction"><b><span style="font-family: Book Antiqua; font-size: 0.8em;">GWP 2019 Prediction</b></h2>
<p><span style="font-family: Times New Roman; font-size: 1em;">For prediction of Gross Written Premium for 2019, we consider the two classification methods that yielded best results from the GWP 2018 prediction: classification trees and logistic regression. 
The variable previously used for the Gross Written Premium prediction for 2018: “Up_Down”, can be used for the prediction of GWP 2019.
Next steps: First, we edit the data frame “myBroker_exp_DF” to exclude all variables recorded for 2015. Second, all 2018 variables have to be included into the data frame (2016 to 2018) and third, the new data frame “myBrokerDF” needs to be rerun to refresh the new variables.
Further on we will follow all the steps that were previously done using the classification tree and logistic regression method to determine the GWP 2018 prediction, to predict the Gross Written Premium prediction for 2019. </p>
<pre><code class="r">
myBroker_exp_DF &lt;- myBDF %&gt;%
  dplyr::mutate(quote_ratio2016 = QuoteCount_2016/ Submissions_2016,
                quote_ratio2017 = QuoteCount_2017/ Submissions_2017,
                quote_ratio2018 = QuoteCount_2018/ Submissions_2018,
                hit_ratio16 = PolicyCount_2016/ QuoteCount_2016,
                hit_ratio17 = PolicyCount_2017/ QuoteCount_2017,
                hit_ratio18 = PolicyCount_2018/ QuoteCount_2018,
                success_ratio16_18 = PolicyCount_2016 + PolicyCount_2017 + PolicyCount_2018/
                  Submissions_2016 + Submissions_2017 + Submissions_2018, Up_Down)  %&gt;%
  select(-Submissions_2015, -QuoteCount_2015, -PolicyCount_2015, -AvgTIV_2015, -AvgQuote_2015, 
         -GWP_2015, -Submissions_2014, -QuoteCount_2013, -QuoteCount_2014, -AvgQuote_2013, -AvgQuote_2014)

myBroker_exp_DF$Up_Down &lt;- as.factor(myBroker_exp_DF$Up_Down)

myBrokerDF &lt;- myBroker_exp_DF

colnames(myBrokerDF) &lt;- c(&quot;Submissions_3&quot;,  &quot;Submissions_2&quot;,    &quot;Submissions_1&quot;,
                          &quot;QuoteCount_3&quot;,&quot;QuoteCount_2&quot;,    &quot;QuoteCount_1&quot;, &quot;AvgQuote_3&quot;,   &quot;AvgQuote_2&quot;,   
                          &quot;AvgQuote_1&quot;, &quot;PolicyCount_3&quot;,    &quot;PolicyCount_2&quot;,    &quot;PolicyCount_1&quot;,    
                          &quot;GWP_3&quot;,  &quot;GWP_2&quot;,    &quot;GWP_1&quot;,    &quot;AvgTIV_3&quot;, &quot;AvgTIV_2&quot;,
                          &quot;AvgTIV1&quot;, &quot;QR3&quot;, &quot;QR2&quot;, &quot;QR1&quot;, &quot;HR3&quot;, &quot;HR2&quot;, &quot;HR1&quot;,&quot;SR&quot;,&quot;Up_Down&quot;)

trainRows &lt;- createDataPartition(Up_Down, 
                                 p = 0.8, 
                                 list=FALSE)

BrokTrainData &lt;- myBrokerDF[trainRows,]
BrokTestData &lt;- myBrokerDF[-trainRows,]

table(Up_Down)
</code></pre>

<pre><code>## Up_Down
## Down   Up 
##  106   82
</code></pre>
<h2 id="classification-trees_1"><b><span style="font-family: Book Antiqua; font-size: 0.8em;">Classification Trees</b></h2>
<pre><code class="r"># Rpart

# tuning &amp; cross validation
splitEntropy = list(split = c(&quot;information&quot;))

myRparttune &lt;- train(Up_Down ~ ., 
                     data=BrokTrainData, 
                     method=&quot;rpart&quot;,
                     metric=&quot;ROC&quot;,
                     tuneLength = 10,
                     parms = splitEntropy,
                     trControl=trainControl(classProbs=TRUE, 
                                            summaryFunction=twoClassSummary))


plot(myRparttune)
</code></pre>

<p><img alt="" src="../Images/image27.jpg" /><!-- --></p>
<pre><code class="r">myRparttune$results
</code></pre>

<pre><code>##            cp       ROC      Sens      Spec      ROCSD    SensSD    SpecSD
## 1  0.00000000 0.7772342 0.7718559 0.7003976 0.05924325 0.1002510 0.1228265
## 2  0.04713805 0.7781164 0.7738181 0.7072454 0.07481055 0.1036247 0.1352125
## 3  0.09427609 0.7751503 0.7662576 0.6841993 0.07661726 0.1101780 0.1622165
## 4  0.14141414 0.7543121 0.7264026 0.7051762 0.08868316 0.1541780 0.1738824
## 5  0.18855219 0.7481983 0.6496310 0.7975082 0.07593846 0.1569490 0.1859312
## 6  0.23569024 0.7377948 0.6062637 0.8506126 0.06647601 0.1184918 0.1663785
## 7  0.28282828 0.7111638 0.6120016 0.8103259 0.08725597 0.1349080 0.2757272
## 8  0.32996633 0.7013860 0.6280016 0.7747703 0.09657012 0.1555639 0.3190783
## 9  0.37710438 0.6678546 0.6705642 0.6651450 0.11118447 0.1975369 0.4017962
## 10 0.42424242 0.6265475 0.7388536 0.5142413 0.11769807 0.2243999 0.4455393
</code></pre>
<pre><code class="r">myRparttune$bestTune
</code></pre>

<pre><code>##           cp
## 2 0.04713805
</code></pre>
<pre><code class="r">myRparttune$finalModel
</code></pre>

<pre><code>## n= 151 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
##  1) root 151 66 Down (0.56291391 0.43708609)  
##    2) GWP_1&lt; 1218364 53  3 Down (0.94339623 0.05660377) *
##    3) GWP_1&gt;=1218364 98 35 Up (0.35714286 0.64285714)  
##      6) AvgQuote_2&lt; 30219.13 53 23 Down (0.56603774 0.43396226)  
##       12) AvgTIV_2&gt;=7232249 22  3 Down (0.86363636 0.13636364) *
##       13) AvgTIV_2&lt; 7232249 31 11 Up (0.35483871 0.64516129) *
##      7) AvgQuote_2&gt;=30219.13 45  5 Up (0.11111111 0.88888889) *
</code></pre>
<pre><code class="r">print(myRparttune)
</code></pre>

<pre><code>## CART 
## 
## 151 samples
##  25 predictor
##   2 classes: 'Down', 'Up' 
## 
## No pre-processing
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 151, 151, 151, 151, 151, 151, ... 
## Resampling results across tuning parameters:
## 
##   cp          ROC        Sens       Spec     
##   0.00000000  0.7772342  0.7718559  0.7003976
##   0.04713805  0.7781164  0.7738181  0.7072454
##   0.09427609  0.7751503  0.7662576  0.6841993
##   0.14141414  0.7543121  0.7264026  0.7051762
##   0.18855219  0.7481983  0.6496310  0.7975082
##   0.23569024  0.7377948  0.6062637  0.8506126
##   0.28282828  0.7111638  0.6120016  0.8103259
##   0.32996633  0.7013860  0.6280016  0.7747703
##   0.37710438  0.6678546  0.6705642  0.6651450
##   0.42424242  0.6265475  0.7388536  0.5142413
## 
## ROC was used to select the optimal model using the largest value.
## The final value used for the model was cp = 0.04713805.
</code></pre>
<pre><code class="r">par(xpd = NA) 
plot(myRparttune$finalModel)
text(myRparttune$finalModel, cex=.6)
</code></pre>

<p><img alt="" src="../Images/image28.jpg" /><!-- --></p>
<pre><code class="r">myRparttunepredtest &lt;- predict(myRparttune, newdata=BrokTestData)
(myRparttunedConfusion &lt;- table(BrokTestData$Up_Down, myRparttunepredtest))
</code></pre>

<pre><code>##       myRparttunepredtest
##        Down Up
##   Down   18  3
##   Up      3 13
</code></pre>
<pre><code class="r">1-sum(diag(myRparttunedConfusion))/sum(myRparttunedConfusion)
</code></pre>

<pre><code>## [1] 0.1621622
</code></pre>
<pre><code class="r">myRparttunepredprob &lt;- predict(myRparttune, newdata=myBrokerDF, type=&quot;prob&quot;)[,2]
myRparttunedpred &lt;- predict(myRparttune, newdata=myBrokerDF)
(myRparttunedCM &lt;- table(myBrokerDF$Up_Down, myRparttunedpred))
</code></pre>

<pre><code>##       myRparttunedpred
##        Down Up
##   Down   87 19
##   Up      9 73
</code></pre>
<pre><code class="r">1-sum(diag(myRparttunedCM))/sum(myRparttunedCM)
</code></pre>

<pre><code>## [1] 0.1489362
</code></pre>
<pre><code class="r"># ROC
myRparttunePredict &lt;- predict(myRparttune, newdata=myBrokerDF, type=&quot;prob&quot;)
myRparttunePred &lt;- prediction(myRparttunePredict[,2], 
                              myBrokerDF$Up_Down,
                              label.ordering=c( &quot;Down&quot;, &quot;Up&quot;))
myRparttunePerf &lt;- performance(myRparttunePred, &quot;tpr&quot;, &quot;fpr&quot;)

performance(myRparttunePred, &quot;auc&quot;)
</code></pre>

<pre><code>## An object of class "performance"
## Slot "x.name":
## [1] "None"
## 
## Slot "y.name":
## [1] "Area under the ROC curve"
## 
## Slot "alpha.name":
## [1] "none"
## 
## Slot "x.values":
## list()
## 
## Slot "y.values":
## [[1]]
## [1] 0.890359
## 
## 
## Slot "alpha.values":
## list()
</code></pre>
<p><span style="font-family: Times New Roman; font-size: 1em;">The misclassification rate for the classification tree model when validating the test set (myRparttunepredtest) is 18.92 %. 
The accuracy rate for the model was 81.08%. 
<br>The misclassification rate for the classification tree model when validating entire data set (myRparttunedpred) is 15.43 %. 
The accuracy rate for this model was 84.57%. 
<br>The features that appear to be most important for predicting the outcome for the gross written premium prediction for 2019 are Gross Written Premium, Average Quote, and Average Total Insured Value.</p>
<h2 id="logistic-regression_1"><b><span style="font-family: Book Antiqua; font-size: 0.8em;">Logistic Regression</b></h2>
<pre><code class="r"># Logistic regression

# Cross Validation

myLRtrain &lt;- train(Up_Down ~ ., 
                   data=BrokTrainData, 
                   method=&quot;glm&quot;,
                   metric=&quot;ROC&quot;,
                   tuneLength = 10,
                   trControl=trainControl(classProbs=TRUE,
                                          summaryFunction=twoClassSummary))
</code></pre>

<pre><code class="r">myLRtrain$results
</code></pre>

<pre><code>##   parameter       ROC      Sens      Spec      ROCSD    SensSD     SpecSD
## 1      none 0.8936167 0.8720923 0.8428428 0.05939975 0.0736007 0.07988117
</code></pre>
<pre><code class="r">myLRtrain$bestTune
</code></pre>

<pre><code>##   parameter
## 1      none
</code></pre>
<pre><code class="r">myLRtrain$finalModel
</code></pre>

<pre><code>## 
## Call:  NULL
## 
## Coefficients:
##   (Intercept)  Submissions_3  Submissions_2  Submissions_1   QuoteCount_3  
##    -1.150e+00      3.181e-02      2.365e+01      2.356e+01     -1.107e-01  
##  QuoteCount_2   QuoteCount_1     AvgQuote_3     AvgQuote_2     AvgQuote_1  
##    -1.723e-01     -5.991e-02     -1.062e-03      1.214e-03     -8.091e-04  
## PolicyCount_3  PolicyCount_2  PolicyCount_1          GWP_3          GWP_2  
##     2.313e+01      2.278e+01      7.174e-01      8.688e-06     -3.028e-04  
##         GWP_1       AvgTIV_3       AvgTIV_2        AvgTIV1            QR3  
##     3.162e-04     -1.397e-05     -1.837e-06      1.062e-05      2.361e+01  
##           QR2            QR1            HR3            HR2            HR1  
##     1.494e+01      2.155e+01      1.019e+00      1.949e+00      2.520e+00  
##            SR  
##    -2.348e+01  
## 
## Degrees of Freedom: 150 Total (i.e. Null);  125 Residual
## Null Deviance:       206.9 
## Residual Deviance: 3.366e-08     AIC: 52
</code></pre>
<pre><code class="r">print(myLRtrain)
</code></pre>

<pre><code>## Generalized Linear Model 
## 
## 151 samples
##  25 predictor
##   2 classes: 'Down', 'Up' 
## 
## No pre-processing
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 151, 151, 151, 151, 151, 151, ... 
## Resampling results:
## 
##   ROC        Sens       Spec     
##   0.8936167  0.8720923  0.8428428
</code></pre>
<pre><code class="r">myLRtraintest &lt;- predict(myLRtrain, newdata=BrokTestData)
(myLRtrainConfusion &lt;- table(BrokTestData$Up_Down, myLRtraintest))
</code></pre>

<pre><code>##       myLRtraintest
##        Down Up
##   Down   20  1
##   Up      4 12
</code></pre>
<pre><code class="r">1-sum(diag(myLRtrainConfusion))/sum(myLRtrainConfusion)
</code></pre>

<pre><code>## [1] 0.1351351
</code></pre>
<pre><code class="r">myLRtrainpred &lt;- predict(myLRtrain, newdata=myBrokerDF)
(myLRtrainCM &lt;- table(myBrokerDF$Up_Down, myLRtrainpred))
</code></pre>

<pre><code>##       myLRtrainpred
##        Down  Up
##   Down  105   1
##   Up      4  78
</code></pre>
<pre><code class="r">1-sum(diag(myLRtrainCM))/sum(myLRtrainCM)
</code></pre>

<pre><code>## [1] 0.02659574
</code></pre>
<pre><code class="r"># ROC
myLRPredict &lt;- predict(myLRtrain, newdata=myBrokerDF, type=&quot;prob&quot;)
myLRPred &lt;- prediction(myLRPredict[,2], 
                       myBrokerDF$Up_Down,
                       label.ordering=c( &quot;Down&quot;, &quot;Up&quot;))
myLRPerf &lt;- performance(myLRPred, &quot;tpr&quot;, &quot;fpr&quot;)

performance(myLRPred, &quot;auc&quot;)
</code></pre>

<pre><code>## An object of class "performance"
## Slot "x.name":
## [1] "None"
## 
## Slot "y.name":
## [1] "Area under the ROC curve"
## 
## Slot "alpha.name":
## [1] "none"
## 
## Slot "x.values":
## list()
## 
## Slot "y.values":
## [[1]]
## [1] 0.9983893
## 
## 
## Slot "alpha.values":
## list()
</code></pre>
<p><span style="font-family: Times New Roman; font-size: 1em;">The misclassification rate for the logistic regression model when validating the test set (myLRtraintest) is 13.51%. 
The accuracy rate for the model was 86.49%.
<br>The misclassification rate for the logistic regression model when validating the entire data set (myLRtrainpred) is 2.65%. 
The accuracy rate for the model was 97.35%.</p>
<pre><code class="r">plot(myLRPerf, col=1)
plot(myRparttunePerf, col=2, add=TRUE)
legend(0.7, 0.6, c(&quot;Log. Reg.&quot;, &quot;Class. Tree&quot;), col=1:2, lwd=10)
</code></pre>

<p><img alt="" src="../Images/image29.jpg" /><!-- --></p>
<h2 id="results-gwp-2019_1"><b><span style="font-family: Book Antiqua; font-size: 0.8em;">Results: GWP 2019</b></h2>
<p><span style="font-family: Times New Roman; font-size: 1em;">The performance for the logistic regression model and the classification tree model are represented by the red (Class Tree) and black (Log Reg) curves. 
The AUC for the Class Tree is 87.51 and the AUC for the Log Reg is 99.11.</p>
<h2 id="conclusion"><b><span style="font-family: Book Antiqua; font-size: 0.8em;">Conclusion</b></h2>
<p><span style="font-family: Times New Roman; font-size: 1em;">To conclude with regards to the Broker Segmentation, task 1: the hierarchical and k-means clustering methods were performed and analyzed. Of the two methods, we preferred the k-means clustering approach. 
Although both methods performed well during evaluation, the K-means clustering approach appeared to perform slightly better and provided better results. 
The PCA scores and average silhouette coefficients obtained from this method presented better assignment of clusters overall.</p>
<p><br><span style="font-family: Times New Roman; font-size: 1em;">With regards to Gross Written Premium Prediction, task 2: In comparison to the classification tree and logistic regression, the random forest method, appeared to perform better in the ROC curves. 
The accuracy rate was 94.69% and misclassification rate 5.32%. 
This method also provided the highest area under the curve (AUC) = 99%, and high rates for specificity (95%) and sensitivity (94%). 
While this method seems to be the highest performer, we considered that the results were unrealistic or “too good to be true” and high performance could be attributed to data leakage or noise. 
At times when a complex model, like random forest is used, in a small data set such as the one utilized in this case, the function does not have enough information to train on. 
Hence, the the best approach for GWP 2018 prediction is the Logistic regression model. The predicted outcomes appeared more meaningful and useful for consideration, and the model seemed to provide more realistic results. 
Performance results obtained from the model were satisfactory with low misclassification rate of 19.68% and elevated accuracy rate of 80.32%. 
The AUC was 91.12%, sensitivity 78% and specificity 82%. 
The features most important for prediction were average quote counts for 2015, average total insured value for 2015 and 2017, hit ratio for 2015.</p>
<p><br><span style="font-family: Times New Roman; font-size: 1em;">To predict whether the gross premium will increase or decrease for 2019: the logistic regression model appeared to perform better in the ROC curve. 
The accuracy rate for this model was 97.35% and the misclassification rate was 2.65%. 
The AUC for this model was 99%, specificity was 98%. and sensitivity was 96.34 %. 
Again, due to unrealistic performance results, we would prefer the other method. 
Our recommendation for 2019 prediction has to be the classification tree model as it also provided high performance values. 
The AUC for this model was 87.51%, specificity was 84% and sensitivity was 85.3%. 
The misclassification rate obtained was 15.43% and the accuracy rate for this model was 84.57%. 
The most important features for prediction appear to be GWP 2016, 2017, and 2018, policy counts 2016, 2017, and 2018, as well as the avg. quote for 2017 and 2018, and avg. TIV for 2017 and 2018.</p></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js" defer></script>
        <script src="../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form>
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
